{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4239082",
   "metadata": {},
   "source": [
    "# **Verification Lab2 - NLP Medical Question Filtering**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c300ba",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a13894",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5344558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import uuid\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49a8c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information:\n",
      "==================================================\n",
      "Python version: 3.11.0 | packaged by conda-forge | (main, Jan 14 2023, 12:25:12) [Clang 14.0.6 ]\n",
      "Platform: macOS-15.6-arm64-arm-64bit\n",
      "Architecture: ('64bit', '')\n",
      "\n",
      "Conda Environment: CDT_DAIR_v1\n",
      "\n",
      "keras-tuner             1.4.7\n",
      "matplotlib              3.10.6\n",
      "matplotlib-inline       0.1.7\n",
      "numpy                   1.23.5\n",
      "pandas                  2.3.2\n",
      "scikit-learn            1.7.1\n",
      "sentence-transformers   5.1.1\n",
      "tensorflow              2.12.0\n",
      "tensorflow-estimator    2.12.0\n"
     ]
    }
   ],
   "source": [
    "# Check Installs\n",
    "#\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.architecture()}\")\n",
    "print()\n",
    "\n",
    "conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'Unknown')\n",
    "print(f\"Conda Environment: {conda_env}\")\n",
    "print()\n",
    "\n",
    "!pip list | grep -E \"(pandas|numpy|matplotlib|scikit-learn|tensorflow|tensorflow-metal|keras-tuner|sentence-transformers)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad28e1b",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f6fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Setup\n",
    "#\n",
    "\n",
    "#---- Run Parameters --------------------------------\n",
    "run_name = 'Test_Run_2'\n",
    "\n",
    "#----------------------------------------------------\n",
    "\n",
    "# Folder paths\n",
    "local_project_folder = Path.cwd().parent\n",
    "data_folder = local_project_folder.joinpath('Data')\n",
    "if not data_folder.exists():\n",
    "    raise FileNotFoundError(f'{data_folder} does not exist')\n",
    "results_folder = local_project_folder.joinpath('Results')\n",
    "if not results_folder.exists():\n",
    "    raise FileNotFoundError(f'{results_folder} does not exist')\n",
    "\n",
    "# Run Results\n",
    "# run_name = f\"Run_{run_name}_{datetime.now().strftime('%Y%m%d')}\"\n",
    "run_results_folder = results_folder.joinpath(f'{run_name}')\n",
    "run_results_folder.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "del local_project_folder, results_folder, run_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb086fc",
   "metadata": {},
   "source": [
    "***\n",
    "# WIP - Feature Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualise feature entanglement etc, using clustering\n",
    "\n",
    "# Word embeddings disentanglement: https://aclanthology.org/2020.aacl-main.72.pdf\n",
    "# look at PCA, t-SNE and UMAP eg https://voxel51.com/blog/how-to-visualize-your-data-with-dimension-reduction-techniques\n",
    "\n",
    "# Full example of similarity etc: https://www.perplexity.ai/search/i-have-embedded-text-sentences-kJqSX900ReCGPgkvTZyLkQ?preview=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad69f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original text and embeddings\n",
    "query_df = pd.read_pickle(run_results_folder.joinpath('query_data_embeddings.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6197b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_semantic_similarity(self):\n",
    "        '''Compute semantic similarity between original and PGD embeddings'''\n",
    "        # Cosine similarity (most common for sentence embeddings)\n",
    "        cosine_similarities = []\n",
    "        for i in range(len(self.original_embeddings)):\n",
    "            cos_sim = cosine_similarity(\n",
    "                self.original_embeddings[i:i+1], \n",
    "                self.pgd_embeddings[i:i+1]\n",
    "            )[0,0]\n",
    "            cosine_similarities.append(cos_sim)\n",
    "\n",
    "        # Euclidean distance\n",
    "        euclidean_dists = []\n",
    "        for i in range(len(self.original_embeddings)):\n",
    "            euc_dist = euclidean_distances(\n",
    "                self.original_embeddings[i:i+1], \n",
    "                self.pgd_embeddings[i:i+1]\n",
    "            )[0,0]\n",
    "            euclidean_dists.append(euc_dist)\n",
    "\n",
    "        return {\n",
    "            'cosine_similarities': cosine_similarities,\n",
    "            'euclidean_distances': euclidean_dists,\n",
    "            'mean_cosine_sim': np.mean(cosine_similarities),\n",
    "            'std_cosine_sim': np.std(cosine_similarities),\n",
    "            'mean_euclidean_dist': np.mean(euclidean_dists),\n",
    "            'std_euclidean_dist': np.std(euclidean_dists)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab368d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890ac57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b491901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Similarity Determine\n",
    "#\n",
    "\n",
    "def calc_semantic_similarity(embedding_model, orig_embeddings, compare_embeddings):\n",
    "\n",
    "    cosine_similarities = embedding_model.similarity(orig_embeddings, compare_embeddings)\n",
    "\n",
    "    return cosine_similarities.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60efc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384) (3, 384)\n",
      "[[ 0.06831154  0.4459902   0.00077163]\n",
      " [ 0.15523376  0.02250158 -0.01895111]\n",
      " [ 0.09924722  0.0597299   0.16938508]]\n",
      "Bad reaction to anti-depression meds, wondering if there's something underlying... Not sure how to ask\n",
      " - Help with a mole              : 0.0683\n",
      " - Why do I cry when I occasionally take valium (as prescribed)?: 0.4460\n",
      " - How to heal a sprain wrist (TFCC injury)?: 0.0008\n",
      "What are these white bumps in my nostrils? Is it infected? They are sensitive to the touch.\n",
      " - Help with a mole              : 0.1552\n",
      " - Why do I cry when I occasionally take valium (as prescribed)?: 0.0225\n",
      " - How to heal a sprain wrist (TFCC injury)?: -0.0190\n",
      "What can I do to avoid these nail infections?\n",
      " - Help with a mole              : 0.0992\n",
      " - Why do I cry when I occasionally take valium (as prescribed)?: 0.0597\n",
      " - How to heal a sprain wrist (TFCC injury)?: 0.1694\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "test_a = query_df.iloc[5:8]\n",
    "test_b = query_df.iloc[9:12]\n",
    "queries_a = test_a['query'].tolist()\n",
    "queries_b = test_b['query'].tolist()\n",
    "embeddings_a = np.array(test_a['query-embedding'].to_list())\n",
    "embeddings_b = np.array(test_b['query-embedding'].to_list())\n",
    "\n",
    "similarities = calc_semantic_similarity(sbert_model, embeddings_a, embeddings_b)\n",
    "\n",
    "print(embeddings_a.shape, embeddings_b.shape)\n",
    "print(similarities)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for idx_i, sentence in enumerate(queries_a):\n",
    "    print(sentence)\n",
    "    for idx_j, sentence2 in enumerate(queries_b):\n",
    "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "295f086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384) (3, 384)\n",
      "[[ 0.06831154  0.4459902   0.00077163]\n",
      " [ 0.15523376  0.02250158 -0.01895111]\n",
      " [ 0.09924722  0.0597299   0.16938508]]\n",
      "Bad reaction to anti-depression meds, wondering if there's something underlying... Not sure how to ask\n",
      " - Help with a mole              : 0.0683\n",
      " - Why do I cry when I occasionally take valium (as prescribed)?: 0.4460\n",
      " - How to heal a sprain wrist (TFCC injury)?: 0.0008\n",
      "What are these white bumps in my nostrils? Is it infected? They are sensitive to the touch.\n",
      " - Help with a mole              : 0.1552\n",
      " - Why do I cry when I occasionally take valium (as prescribed)?: 0.0225\n",
      " - How to heal a sprain wrist (TFCC injury)?: -0.0190\n",
      "What can I do to avoid these nail infections?\n",
      " - Help with a mole              : 0.0992\n",
      " - Why do I cry when I occasionally take valium (as prescribed)?: 0.0597\n",
      " - How to heal a sprain wrist (TFCC injury)?: 0.1694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Quick test\n",
    "test_a = query_df.iloc[5:8]\n",
    "test_b = query_df.iloc[9:12]\n",
    "queries_a = test_a['query'].tolist()\n",
    "queries_b = test_b['query'].tolist()\n",
    "embeddings_a = np.array(test_a['query-embedding'].to_list())\n",
    "embeddings_b = np.array(test_b['query-embedding'].to_list())\n",
    "\n",
    "sim_matrix = cosine_similarity(embeddings_a, embeddings_b)\n",
    "\n",
    "print(embeddings_a.shape, embeddings_b.shape)\n",
    "print(sim_matrix)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for idx_i, sentence in enumerate(queries_a):\n",
    "    print(sentence)\n",
    "    for idx_j, sentence2 in enumerate(queries_b):\n",
    "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e11f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick cosine similarity\n",
    "\n",
    "test_a = query_df.iloc[5:8]\n",
    "test_b = query_df.iloc[9:15]\n",
    "queries_a = test_a['query'].tolist()\n",
    "queries_b = test_b['query'].tolist()\n",
    "embeddings_a = np.array(test_a['query-embedding'].to_list())\n",
    "embeddings_b = np.array(test_b['query-embedding'].to_list())\n",
    "\n",
    "# Compute cosine similarities\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "similarities = sbert_model.similarity(embeddings_a, embeddings_b)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for idx_i, sentence in enumerate(queries_a):\n",
    "    print(sentence)\n",
    "    for idx_j, sentence2 in enumerate(queries_b):\n",
    "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8485935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install umap-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ad1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension reduction and clustering libraries\n",
    "import umap\n",
    "# import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_semantic_similarity(self):\n",
    "        '''Compute semantic similarity between original and PGD embeddings'''\n",
    "        # Cosine similarity (most common for sentence embeddings)\n",
    "        cosine_similarities = []\n",
    "        for i in range(len(self.original_embeddings)):\n",
    "            cos_sim = cosine_similarity(\n",
    "                self.original_embeddings[i:i+1], \n",
    "                self.pgd_embeddings[i:i+1]\n",
    "            )[0,0]\n",
    "            cosine_similarities.append(cos_sim)\n",
    "\n",
    "        # Euclidean distance\n",
    "        euclidean_dists = []\n",
    "        for i in range(len(self.original_embeddings)):\n",
    "            euc_dist = euclidean_distances(\n",
    "                self.original_embeddings[i:i+1], \n",
    "                self.pgd_embeddings[i:i+1]\n",
    "            )[0,0]\n",
    "            euclidean_dists.append(euc_dist)\n",
    "\n",
    "        return {\n",
    "            'cosine_similarities': cosine_similarities,\n",
    "            'euclidean_distances': euclidean_dists,\n",
    "            'mean_cosine_sim': np.mean(cosine_similarities),\n",
    "            'std_cosine_sim': np.std(cosine_similarities),\n",
    "            'mean_euclidean_dist': np.mean(euclidean_dists),\n",
    "            'std_euclidean_dist': np.std(euclidean_dists)\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CDT_DAIR_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
